{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.   데이터 로딩: CSV 파일에서 데이터를 읽어옵니다.\n",
        "2.   기본 정보 확인: 데이터의 기본 정보, 처음 몇 개의 행, 기술 통계량을 확인합니다.\n",
        "3.   결측치 확인 및 처리: 결측치를 확인하고, 수치형 데이터는 평균으로, 범주형\n",
        "4.    데이터는 최빈값으로 대체합니다.\n",
        "5.    레이블 확인: 타겟 변수의 분포를 확인하고 시각화합니다.\n",
        "6.    데이터 인코딩: 범주형 변수를 숫자로 인코딩합니다.\n",
        "7.    상관관계 분석: 특성 간의 상관관계를 히트맵으로 시각화합니다.\n",
        "8.    TensorFlow 데이터셋 생성: 전처리된 데이터를 TensorFlow 데이터셋으로 변환합니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "teRs4n3FGLXu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCWRtjtgGJ2I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 로딩\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(\"데이터 로드 완료. 데이터 shape:\", data.shape)\n",
        "    return data"
      ],
      "metadata": {
        "id": "n8w4r_SWGjLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 기본 정보 확인\n",
        "def check_basic_info(data):\n",
        "    print(\"\\n기본 정보:\")\n",
        "    print(data.info())\n",
        "    print(\"\\n처음 5개 행:\")\n",
        "    print(data.head())\n",
        "    print(\"\\n기술 통계량:\")\n",
        "    print(data.describe())"
      ],
      "metadata": {
        "id": "kywae96KGkXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 결측치 확인 및 처리\n",
        "def handle_missing_values(data):\n",
        "    print(\"\\n결측치 확인:\")\n",
        "    print(data.isnull().sum())\n",
        "\n",
        "    # 결측치 처리 (예: 수치형 데이터는 평균으로, 범주형 데이터는 최빈값으로 대체)\n",
        "    numeric_features = data.select_dtypes(include=[np.number]).columns\n",
        "    categorical_features = data.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "    imputer_numeric = SimpleImputer(strategy='mean')\n",
        "    imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "    data[numeric_features] = imputer_numeric.fit_transform(data[numeric_features])\n",
        "    data[categorical_features] = imputer_categorical.fit_transform(data[categorical_features])\n",
        "\n",
        "    print(\"\\n결측치 처리 후:\")\n",
        "    print(data.isnull().sum())\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "7xsYbMQ2Glc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 레이블 확인\n",
        "def check_labels(data, target_column):\n",
        "    print(f\"\\n레이블({target_column}) 확인:\")\n",
        "    print(data[target_column].value_counts())\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    data[target_column].value_counts().plot(kind='bar')\n",
        "    plt.title(f'{target_column} 분포')\n",
        "    plt.xlabel(target_column)\n",
        "    plt.ylabel('개수')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RIJzeQy8Gmji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 데이터 인코딩\n",
        "def encode_data(data, target_column):\n",
        "    # 범주형 변수 인코딩\n",
        "    le = LabelEncoder()\n",
        "    for column in data.select_dtypes(include=['object']):\n",
        "        if column != target_column:  # 타겟 변수는 제외\n",
        "            data[column] = le.fit_transform(data[column])\n",
        "\n",
        "    # 타겟 변수 인코딩 (필요한 경우)\n",
        "    if data[target_column].dtype == 'object':\n",
        "        data[target_column] = le.fit_transform(data[target_column])\n",
        "\n",
        "    print(\"\\n인코딩 후 데이터 샘플:\")\n",
        "    print(data.head())\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "FveWGpFZGn9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 상관관계 분석\n",
        "def correlation_analysis(data):\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(data.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "    plt.title('특성 간 상관관계')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bcfnySXIGpB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 특성 스케일링\n",
        "def scale_features(data, target_column):\n",
        "    scaler = StandardScaler()\n",
        "    features = data.drop(columns=[target_column])\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "    scaled_data = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "    scaled_data[target_column] = data[target_column]\n",
        "\n",
        "    print(\"\\n스케일링 후 데이터 샘플:\")\n",
        "    print(scaled_data.head())\n",
        "\n",
        "    return scaled_data\n"
      ],
      "metadata": {
        "id": "vLwD1ls2Gp6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메인 함수\n",
        "def main():\n",
        "    # 데이터 파일 경로\n",
        "    file_path = 'your_dataset.csv'\n",
        "\n",
        "    # 타겟 변수명\n",
        "    target_column = 'your_target_column'\n",
        "\n",
        "    # 1. 데이터 로딩\n",
        "    data = load_data(file_path)\n",
        "\n",
        "    # 2. 기본 정보 확인\n",
        "    check_basic_info(data)\n",
        "\n",
        "    # 3. 결측치 처리\n",
        "    data = handle_missing_values(data)\n",
        "\n",
        "    # 4. 레이블 확인\n",
        "    check_labels(data, target_column)\n",
        "\n",
        "    # 5. 데이터 인코딩\n",
        "    data = encode_data(data, target_column)\n",
        "\n",
        "    # 6. 상관관계 분석\n",
        "    correlation_analysis(data)\n",
        "\n",
        "    # 7. 특성 스케일링\n",
        "    scaled_data = scale_features(data, target_column)\n",
        "\n",
        "    # TensorFlow 데이터셋으로 변환\n",
        "    features = scaled_data.drop(columns=[target_column])\n",
        "    labels = scaled_data[target_column]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features.values, labels.values))\n",
        "    print(\"\\nTensorFlow 데이터셋 생성 완료\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = main()"
      ],
      "metadata": {
        "id": "cpQPoXXMGq4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}