{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ML 접근방식"
      ],
      "metadata": {
        "id": "UPy2Xf2cE4wB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siEHqd__ErNL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
        "\n",
        "# 데이터 로딩\n",
        "data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# 특성(X)과 타겟(y) 분리\n",
        "X = data.drop('target_column', axis=1)\n",
        "y = data['target_column']\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 분류 모델 (예: 로지스틱 회귀와 랜덤 포레스트)\n",
        "def ml_classification():\n",
        "    # 로지스틱 회귀\n",
        "    log_reg = LogisticRegression()\n",
        "    log_reg.fit(X_train_scaled, y_train)\n",
        "    log_reg_pred = log_reg.predict(X_test_scaled)\n",
        "    log_reg_accuracy = accuracy_score(y_test, log_reg_pred)\n",
        "    print(f\"Logistic Regression Accuracy: {log_reg_accuracy}\")\n",
        "\n",
        "    # 랜덤 포레스트\n",
        "    rf_clf = RandomForestClassifier()\n",
        "    rf_clf.fit(X_train_scaled, y_train)\n",
        "    rf_clf_pred = rf_clf.predict(X_test_scaled)\n",
        "    rf_clf_accuracy = accuracy_score(y_test, rf_clf_pred)\n",
        "    print(f\"Random Forest Classifier Accuracy: {rf_clf_accuracy}\")\n",
        "\n",
        "# 회귀 모델 (예: 선형 회귀와 랜덤 포레스트)\n",
        "def ml_regression():\n",
        "    # 선형 회귀\n",
        "    lin_reg = LinearRegression()\n",
        "    lin_reg.fit(X_train_scaled, y_train)\n",
        "    lin_reg_pred = lin_reg.predict(X_test_scaled)\n",
        "    lin_reg_mse = mean_squared_error(y_test, lin_reg_pred)\n",
        "    lin_reg_r2 = r2_score(y_test, lin_reg_pred)\n",
        "    print(f\"Linear Regression MSE: {lin_reg_mse}, R2: {lin_reg_r2}\")\n",
        "\n",
        "    # 랜덤 포레스트\n",
        "    rf_reg = RandomForestRegressor()\n",
        "    rf_reg.fit(X_train_scaled, y_train)\n",
        "    rf_reg_pred = rf_reg.predict(X_test_scaled)\n",
        "    rf_reg_mse = mean_squared_error(y_test, rf_reg_pred)\n",
        "    rf_reg_r2 = r2_score(y_test, rf_reg_pred)\n",
        "    print(f\"Random Forest Regressor MSE: {rf_reg_mse}, R2: {rf_reg_r2}\")\n",
        "\n",
        "# ML 모델 실행\n",
        "print(\"ML Classification Results:\")\n",
        "ml_classification()\n",
        "print(\"\\nML Regression Results:\")\n",
        "ml_regression()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL 접근방식"
      ],
      "metadata": {
        "id": "k6oCNtQVE6KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
        "\n",
        "# 분류를 위한 DL 모델\n",
        "def dl_classification(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 회귀를 위한 DL 모델\n",
        "def dl_regression(input_shape):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# DL 분류 모델 학습 및 평가\n",
        "def run_dl_classification():\n",
        "    model = dl_classification(X_train_scaled.shape[1], len(np.unique(y)))\n",
        "    history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    print(f\"DL Classification Accuracy: {accuracy}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# DL 회귀 모델 학습 및 평가\n",
        "def run_dl_regression():\n",
        "    model = dl_regression(X_train_scaled.shape[1])\n",
        "    history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"DL Regression MSE: {mse}, R2: {r2}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# DL 모델 실행\n",
        "print(\"\\nDL Classification Results:\")\n",
        "dl_clf_history = run_dl_classification()\n",
        "print(\"\\nDL Regression Results:\")\n",
        "dl_reg_history = run_dl_regression()"
      ],
      "metadata": {
        "id": "t6ht3Sr1E-n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화"
      ],
      "metadata": {
        "id": "fz85y5ZcFCyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GZnG-97GFNrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML"
      ],
      "metadata": {
        "id": "cXVw-pDjFRTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ml_visualization(y_true, y_pred, y_pred_proba=None, model_name=\"ML Model\"):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 혼동 행렬 (Confusion Matrix)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    # 실제 값 vs 예측 값 (회귀의 경우)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.scatter(y_true, y_pred, alpha=0.5)\n",
        "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
        "    plt.title(f'{model_name} Actual vs Predicted')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "\n",
        "    # ROC 곡선 (분류의 경우, 이진 분류 가정)\n",
        "    if y_pred_proba is not None:\n",
        "        plt.subplot(1, 3, 3)\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'{model_name} ROC Curve')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 사용 예시 (분류)\n",
        "ml_visualization(y_test, log_reg_pred, log_reg.predict_proba(X_test_scaled), \"Logistic Regression\")\n",
        "ml_visualization(y_test, rf_clf_pred, rf_clf.predict_proba(X_test_scaled), \"Random Forest Classifier\")\n",
        "\n",
        "# 사용 예시 (회귀)\n",
        "ml_visualization(y_test, lin_reg_pred, model_name=\"Linear Regression\")\n",
        "ml_visualization(y_test, rf_reg_pred, model_name=\"Random Forest Regressor\")"
      ],
      "metadata": {
        "id": "wlb0h7vRFOlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL"
      ],
      "metadata": {
        "id": "pE-wUg4OFSne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dl_visualization(history, y_true, y_pred, model_name=\"DL Model\"):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # 학습 곡선\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} Learning Curve - Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # 정확도 또는 MAE 곡선\n",
        "    plt.subplot(2, 2, 2)\n",
        "    if 'accuracy' in history.history:\n",
        "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title(f'{model_name} Learning Curve - Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "    else:\n",
        "        plt.plot(history.history['mae'], label='Training MAE')\n",
        "        plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "        plt.title(f'{model_name} Learning Curve - MAE')\n",
        "        plt.ylabel('MAE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    # 실제 값 vs 예측 값\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.scatter(y_true, y_pred, alpha=0.5)\n",
        "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
        "    plt.title(f'{model_name} Actual vs Predicted')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "\n",
        "    # 예측 오차 분포\n",
        "    plt.subplot(2, 2, 4)\n",
        "    error = y_pred - y_true\n",
        "    plt.hist(error, bins=30)\n",
        "    plt.title(f'{model_name} Prediction Error Distribution')\n",
        "    plt.xlabel('Prediction Error')\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 사용 예시 (분류)\n",
        "dl_visualization(dl_clf_history, y_test, np.argmax(dl_clf_model.predict(X_test_scaled), axis=1), \"DL Classification\")\n",
        "\n",
        "# 사용 예시 (회귀)\n",
        "dl_visualization(dl_reg_history, y_test, dl_reg_model.predict(X_test_scaled).flatten(), \"DL Regression\")\n"
      ],
      "metadata": {
        "id": "hhPQIMhXFPz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}